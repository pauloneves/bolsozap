#%% [markdown]
# # An√°lise de um grupo Bolsonarista no WhatsApp
#
# Ap√≥s alguns surpreendentes resultados no primeiro turno da elei√ß√£o de 2018, resolvi acompanhar um grupo de WhatsApp da campanha do candidato Jair Bolsonaro. Tinha curiosidade entender como funcionava t√£o importante engrenagem da campanha.
#
# A quantidade de mensagens √© enorme. N√£o d√° para ler tudo. Resolvi ent√£o fazer an√°lise de dados para compreender padr√µes seu funcionamento.

#%%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()
from dateutil.parser import parse as dtparse
get_ipython().run_line_magic('matplotlib', 'inline')
plt.rcParams['figure.figsize'] = [14, 7]
plt.rc('axes', titlesize=20)

from IPython.core.display import display, HTML
def printBig(s):
    display(HTML('<span style="font-size:2em;color:darkblue">{:s}</span>'.format(s)))


#%% [markdown]
# ## Reportagens sobre a campanha no WhatsApp
#
# Algumas reportagens sobre o esquema de divulga√ß√£o:
# - [El Pa√≠s - A m√°quina de ‚Äòfake news‚Äô nos grupos a favor de Bolsonaro no WhatsApp](https://brasil.elpais.com/brasil/2018/09/26/politica/1537997311_859341.html)
# - [Folha - Estudo aponta para automa√ß√£o no envio de mensagens e orquestra√ß√£o entre grupos de WhatsApp pr√≥-Bolsonaro](https://www1.folha.uol.com.br/poder/2018/10/estudo-aponta-para-automacao-no-envio-de-mensagens-e-orquestracao-entre-grupos-de-whatsapp-pro-bolsonaro.shtml)
# - [Folha - Grupos de WhatsApp simulam organiza√ß√£o militar e compartilham apoio a Bolsonaro](https://www1.folha.uol.com.br/poder/2018/10/grupos-de-whatsapp-simulam-organizacao-militar-e-compartilham-apoio-a-bolsonaro.shtml)
# - [BBC - How WhatsApp is being abused in Brazil's elections](https://www.bbc.com/news/technology-45956557)
# - [New York Times - Disinformation Spreads on WhatsApp Ahead of Brazilian Election](https://www.nytimes.com/2018/10/19/technology/whatsapp-brazil-presidential-election.html)
#
# ## Mas as postagens s√£o mentiras?
#
# **Sim.**
#
# N√£o vou abordar isto aqui, porque basta acompanhar um pouco os grupos para perceber que **n√£o h√° a m√≠nima preocupa√ß√£o com a verdade**. O El Pais publicou uma [boa cole√ß√£o de mentiras](https://brasil.elpais.com/especiais/2018/eleicoes-brasil/conversacoes-whatsapp/) nos grupos Bolsonaristas.
#
# Voc√™ pode ter mais trabalho para chegar √† mesma conclus√£o, como fez a [Ag√™ncia](https://piaui.folha.uol.com.br/lupa/2018/10/17/whatsapp-lupa-usp-ufmg-imagens/) [Lupa](https://piaui.folha.uol.com.br/lupa/2018/10/18/imagens-falsas-whatsapp-presidenciaveis-lupa-ufmg-usp/) e os [pesquisadores da UFMG](https://www.eleicoes-sem-fake.dcc.ufmg.br/), para mim basta ver que boa parte das not√≠cias s√£o de imagens como estas:
#
# - Jogo do Bicho fazendo propaganda para Haddad.
# - Propaganda Haddad para presid√°rios.
#
# <img alt="Jogo do Bicho fazendo propaganda para Haddad" src="jogo-do-bicho-haddad.jpg" width="29.465%" style="float:left;" align="top"><img alt="Propaganda para presidi√°rios" src="panfleto-presidiarios.jpg" width="70%" style="float:right;" align="top">
#
#
#

#%%
#Parse de arquivo para dataframe
#whatsAppExported = 'https://drive.google.com/file/d/1tXBKAsAEy_wPI8h8xvsyXy-vJB0_J78c/view?usp=sharing'
whatsAppExported = "conversas/Conversa do WhatsApp com BOLSONARO, o Mito ! üòéüëâüëâ.txt"

# exportar arquivo Abrindo grupo ‚Üí configura√ß√µes ‚Üí mais ‚Üí exportar conversa
# um parse ing√™nuo

import urllib.request
import re
import pandas as pd

inicioRE = re.compile(r'^(\d\d/\d\d/\d{4} \d\d:\d\d) - (.*)')
dadosRE = re.compile('^\u200e?\u202a(?P<fone>.*)\u202c'  + r'(?P<tipo>.) *(?P<texto>.*)')
foneRE = re.compile('[^0-9]+')
with open(whatsAppExported, encoding='utf8') as f:
    dados = []
    msg = []
    obs = {} # uma √∫nica observa√ß√£o
    txt = []
    for line in f:
        m = inicioRE.match(line)
        if m:
            if obs:
                obs['texto'] = '\n'.join(txt)
                dados.append(obs)
                obs = {}
                txt = []

            obs['data'] = pd.to_datetime(m.group(1), dayfirst=True) #brasil
            line = m.group(2)
            m = dadosRE.match(line)
            if m:
                grupos = m.groupdict()
                obs.update(grupos)

                obs['pais'], obs['uf'], obs['tel'] = foneRE.split(grupos['fone'][1:], #tirando o +
                                                                  maxsplit=2)
                txt = [obs['texto']]
            else:
                txt.append(line)
        else:
            txt.append(line)
        date = line[:16]

df = pd.DataFrame(dados)


#%%
# Categorizando as mensagens atribuindo um tipo para cada.
df.loc[(df.tipo==':') & (df.texto.str.contains('<Arquivo de m√≠dia oculto>') ), 'tipo'] = 'midia'
df.loc[(df.tipo==':') & (df.texto.str.contains('Acesse este link para entrar no meu grupo do WhatsApp')), 'tipo'] = 'convite'
df.loc[(df.tipo==':') & (df.texto.str.contains('youtu.?be')), 'tipo'] = 'youtube'
df.loc[(df.tipo==':') & (df.texto.str.contains('https://www.facebook.com', case=False)), 'tipo'] = 'facebook'
df.loc[(df.tipo==':') & (df.texto.str.contains('https?://', case=False)), 'tipo'] = 'link'
df.loc[(df.tipo==':') & (df.texto.str.contains('Esta mensagem foi apagada')), 'tipo'] = 'apagada'
df.loc[(df.texto.str.contains('^removeu')), 'tipo'] = 'banimento'
df.loc[(df.texto.str.contains('^entrou usando o')), 'tipo'] = 'assinatura'
df.loc[(df.texto.str.contains('saiu$', case=False)), 'tipo'] = 'desistencia'
df.loc[(df.tipo==':'), 'tipo'] = 'texto'
df.loc[(df.tipo.str.strip().str.len()==0) & (df.texto.str.contains('alterado para')), 'tipo'] = 'muda-tel'
df.loc[(df.tipo.str.strip().str.len()==0), 'tipo']= np.NaN

tipos_msg = ['midia', 'youtube', 'facebook', 'link', 'texto']

#with pd.option_context("display.max_rows", 1000):
#    display(df[df.tipo == ':'])


#%%
#transformando em categoria
c = list(df.columns)
c.remove('texto')
c.remove('data')
df.loc[:, c] = df.loc[:, c].astype('category')

#%% [markdown]
# M√∫mero de mensagens de cada tipo

#%%
tipos = df.groupby('tipo').size()

display(tipos.sort_values(ascending=False))


#%%
df.head()


#%%
df.info()


#%%
# pegando alguns metadados do grupo
msg_criacao = df.loc[(df.tipo.isna()) & (df.texto.str.contains('criou o grupo '))]
data_criacao = msg_criacao.data

#isso daqui s√≥ lista os moderadores que est√£o participando ativamente do grupo
#TODO: pegar quem altera nome do grupo
msgs_moderacao = pd.concat([df.loc[df.tipo == 'banimento'], msg_criacao])
moderadores = msgs_moderacao.groupby('fone').size().reset_index(name ='nivel_atividade')
moderadores = moderadores[moderadores.nivel_atividade > 0]
print(f'O grupo tem {len(moderadores)} moderadores ativos')

#%% [markdown]
# ## Frequ√™ncia de mensagens
#
# Analisando a frequ√™ncia com que as mensagens s√£o postadas.

#%%
#vamos tirar o dia de cria√ß√£o do grupo, e primeiro e √∫ltimo dia
#pois estes est√£o incompletos e bagun√ßarima as m√©dias
import datetime
data_entrou = df.loc[(df.tipo.isna()) & (df.texto.str.contains('entrou')), ['data']]
primeiro_dia = data_entrou.data.dt.normalize() + datetime.timedelta(days=1)
primeiro_dia = primeiro_dia.iat[0]
ultimo_dia = df.loc[:, 'data'].max().normalize()
print(f'Primeiro dia completo: {primeiro_dia}\n√πltimo dia: {ultimo_dia}')


#%%
#Para an√°lise de frequ√™ncia, tirar o dia em que entrou e o dia em que fez o backup
#e usar apenas as mensagens de conte√∫do, excluindo modera√ß√µes ou quem entrou e saiu
df['finde'] = df.data.dt.weekday.isin([5,6])
df_freq = df[(df.data >= primeiro_dia) & (df_freq.data < ultimo_dia) & (df.tipo.isin(tipos_msg))]

msg_media = df_freq.groupby(df_freq.data.dt.day).size().mean()
printBig('{:.0f} mensagens por dia (m√©dia)'.format(msg_media))


#%%
msg_media_dia_util = df_freq[~df_freq.finde].groupby(df_freq.data.dt.day).size().mean()
msg_media_finde = df_freq[df_freq.finde].groupby(df_freq.data.dt.day).size().mean()

printBig('{:.0f} nos dias √∫teis x {:.0f} nos findes'.format(msg_media_dia_util, msg_media_finde))
if msg_media_dia_util > msg_media_finde:
    print("Aumenta {:.1%} nos dias √∫teis".format(msg_media_dia_util/msg_media_finde - 1))
else:
    print("Aumenta {:.1%} nos fins de semana".format(msg_media_finde/msg_media_dia_util - 1))

#%% [markdown]
# Bem interessante. Ser√° que as pessoas enviando mensagens folgam no fim de semana? Vamos ver qu√£o maior √© o n√∫mero de mensagem em dias √∫teis em rela√ß√£o ao fim de semana.

#%%
import dateutil.parser
df_freq_por_dia =  df_freq.groupby(df_freq.data.dt.date).size()

ax = df_freq_por_dia.plot.line()
ax.set_xticks(df_freq.data.dt.date.unique())
ax.set_xticklabels(df_freq.data.dt.date.unique())

[label.set_color('blue') for label in ax.get_xticklabels() if dtparse(label.get_text()).weekday() in [5,6]]
ax.set_title("Postagens por dia (finde em azul)", loc='left')
ax.tick_params(axis='x', labelrotation=70)

#%% [markdown]
# Pelo visto n√£o h√° rela√ß√£o entre o n√∫mero de posts e o fim de semana. Parece haver alguma redu√ß√£o, mas nada significativo.

#%%
plt.hist(df_freq.data.dt.hour, bins=24);
plt.gca().set_title('Postagens por hora', loc='left');

#%% [markdown]
# O esperado √© ter bem menos mensagens de madrugada. Caso contr√°rio s√£o rob√¥s, gente paga, ou bolsonaristas com TOC e afetamina. N√£o acho que haja muita diferen√ßa entre as op√ß√µes poss√≠veis.

#%%
percentagem_midia = (tipos.loc[['midia', 'youtube']].sum() /
                     tipos.loc[['midia', 'youtube', 'texto']].sum())


printBig('{:.2%} s√£o v√≠deo, √°udio ou imagens'.format(percentagem_midia))

#%% [markdown]
# Percentual das mensagens que s√£o v√≠deo ou imagens. Multim√≠dia √© caro de produzir. Isto √© uma boa indica√ß√£o que h√° uma infraestrutura por tr√°s gerando conte√∫do para estes f√≥runs.

#%%
printBig('{:d} pessoas diferentes postaram'.format(df.tel.unique().size))

#%% [markdown]
# Um grupo de WhatsApp  pode ter no m√°ximo **256 pessoas**. Um n√∫mero grande pessoas postando indica v√°rias pessoas reais participando e que o grupo est√° cumprindo seu papel de divulga√ß√£o. Note que nem todas as pessoas que postaram estavam presentes no grupo ao mesmo tempo. As pessoas v√£o entrando e saindo.

#%%
#tabela ddi editada na m√£o, c√≥digos originais no outro arquivo
ddi = pd.read_table('ddi-paises-sem-duplicadas.tab', names=['ddi', 'pais_nome', 'continente'])

# efeito colateral: remove os participantes que est√£o nos contatos de quem gerou o arquivo
# vai remover pelo menos quem gerou o arquivo
df_pais = df.merge(ddi, left_on='pais', right_on='ddi')


df_pais.groupby('pais_nome').size().sort_values().plot.barh(color='lightslategray')
plt.ylabel("")
plt.gca().set_title("Postagens por pa√≠s", loc='left')
plt.yticks(fontsize=18);

#%% [markdown]
# √â estranho ter gente fora do Brasil. Mas brasileiro est√° espalhado no mundo todo. Algumas das reportagens afirmam que a campanha se vale de n√∫meros no exterior para n√£o ficarem ao alcance das leis brasileiras
#%% [markdown]
# ### N√∫meros que mais postam

#%%
iiq.values[0]


#%%
num_posts = df_freq.groupby('fone').size().sort_values(ascending=False)
iiq = num_posts.quantile([.25, .5, .75]).values
outliers_limit = iiq[2] + (iiq[2] - iiq[0]) * 1.5
num_bins=30
ax = num_posts.plot.hist(bins=num_bins)
ax.set_title('Distribui√ß√£o de n¬∫ postagens', loc='left')
ax.axvline(outliers_limit, linestyle='--', label="Obssessivos", color='darkred');

#%% [markdown]
# Em uma distribui√ß√£o normal, quem est√° √† direita da linha tracejada, normalmente seria considerado um outlier, isto √©, um _"ponto fora da curva"_ por postar demais. Vou considerar como obsessivo apenas quem postou ainda bem mais do que os outros.

#%%
hist, _ = np.histogram(num_posts.values, bins=num_bins)
apos_buraco = False;
for i, v in enumerate(hist):
    if not apos_buraco and v == 0:
        apos_buraco = True;
    elif apos_buraco and v > 0:
        break
obsessivos_fones = num_posts[num_posts >= (num_posts.max()/num_bins * i)].index


#%%
obsessivos_mask = num_posts.index.isin(obsessivos_fones)
obsessivos = num_posts[obsessivos_mask]
cores = np.where(obsessivos_mask, 'darkblue', 'lightslategrey')

ax = num_posts.plot.bar(color=cores, width=1, edgecolor='slategrey')
ax.tick_params(labelbottom=False)
ax.grid(False)
ax.set_facecolor('white')
percentual_msgs = obsessivos.sum()/num_posts.sum()
ax.set_title("{:.0%} das mensagens postadas por {:d} usu√°rios".format(percentual_msgs, obsessivos.size),
             loc='left')
ax.legend(["{:.0%} das postagens".format(percentual_msgs)], prop={'size': 16}, loc="center");

#%% [markdown]
# Cada coluna √© um n√∫mero de telefone e a altura representa quantas postagens cada um fez.
#
# H√° um usu√°rio que postou muito mais do que os outros. Foi mais que o dobro do segundo colocado.
#
# Vamos ver se os sujeitos que mais postam costumam dormir.

#%%
df_freq[df_freq.fone.isin(obsessivos.index)].    groupby(["fone", df_freq.data.dt.hour]).size().    unstack(0)    .sort_values(df_freq.sum(), axis=1, ascending=False).drop("sum")
    #.plot.line(subplots=True);
#ax.set_title('Postagem por hora dos que mais postam', loc='left');


#%%
#Fun√ß√£o auxiliar para plotar todos histogramas de uma categoria
#linhas verticais para real√ßar os outliers
def show_histograms(df, ax, sharey=False):
    df_hist = df[['intervalo', 'fone']].dropna().set_index('intervalo').resample('20min').count()
    ax = df_hist.plot.bar()
    subtitle = "obsessivo"
    ax.set_title(subtitle, loc="left")

    quartiles = df.intervalo.quantile([0, .25, .75, 1])
    iqr =  quartiles.loc[.75] - quartiles.loc[.25]
    out_lower = quartiles.loc[.25] - iqr * 1.5
    out_upper = quartiles.loc[.75] + iqr * 1.5
    if out_lower > df_hist.index[0] and out_lower >= quartiles.loc[0]:
        ax.axvline(out_lower, color="darkred", linestyle='--')
    if out_upper < df_hist.index[-1] and out_upper <= quartiles.loc[1]:
        ax.axvline(out_upper, color="darkred", linestyle='--')
show_histograms(obsessivo, ['intervalo'], None)
#obsessivo[['intervalo', 'fone']].dropna().set_index('intervalo').sort_index().resample('20min').count()


#%%

ax=None

fig, axis = plt.subplots(nrows=obsessivos.size, ncols=1, sharex=True, sharey=False)
fig.subplots_adjust(hspace=.6)


for i, (fone, obsessivo) in enumerate(df[df.fone.isin(obsessivos.index)].groupby('fone')):
    obsessivo.loc[:, 'intervalo'] = (obsessivo.data - obsessivo.data.shift(1)).copy()
    #display(obsessivo[obsessivo.intervalo > pd.to_timedelta(0)].quantile([.75, .9, .95, .99]))
    show_histograms(obsessivo, ['intervalo'], axis[i])#.groupby(obsessivo.data.dt.floor(freq='H')).size()
    #print(intervalo_postagem.quantile([.75, .9, .95, .99]))
ax.legend(metade.index)
#ax.grid(xdata=pd.date_range(start=data_criacao.iat[0], end=ultimo_dia, freq='D') )
ax.set_title('Postagem por hora dos que mais postam', loc='left');


#%%
obsessivo = df[df.fone=='+55 94 9147-8106'].copy()


#%%
obsessivo['intervalo'] = obsessivo.data - obsessivo.data.shift(1)


#%%
obsessivo.sort_values('intervalo', ascending=False)

#%% [markdown]
# ### Como os administrados postam?
#
# Alguns dos administradores n√£o est√£o entre os que mais postaram. Esta √© uma t√°tica para manter o grupo caso as contas de muitas postagens sejam bloqueadas. Na primeira vez que medi nenhum dos administradores estavam entre os que mais postavam, na segunda, ap√≥s a elei√ß√£o e o bloqueio do grupo, um deles passou a postar bastante.

#%%
#Posta muito se 95% postarem menos do que ele
posts_admin =df.merge(moderadores, on='fone').fone.value_counts().reset_index(name='num_posts')
posts_admin['Posta muito'] = posts_admin.num_posts > df.fone.value_counts().quantile(.95)
posts_admin[['num_posts', 'Posta muito']]


#%%
#mais complicado do que deveria
num_dias_posts_admins =   len(df[df.data > data_criacao.iat[0]]      .merge(moderadores, on='fone')      .groupby(['fone', df[df.data > data_criacao.iat[0]].data.dt.date])      .size()      .reset_index()      .data      .unique())

printBig('{:d} dias com posts dos admins'.format(num_dias_posts_admins))

#%% [markdown]
# No dia 15 de outubro, que foi o dia em que entrei no grupo, neste dia os administradores postavam √† be√ßa, mas subtamente pararam. Por que?
#%% [markdown]
# ### Postagem por estado

#%%
df_ddd = pd.DataFrame(columns=["Prefixo", "Estado", "Principais cidades(capitais em negrito)"],
                      data=[
                        ["11", "S√£o Paulo", "S√£o Paulo/Guarulhos/S√£o Bernardo do Campo/Santo Andr√©/Osasco/Jundia√≠"],
                        ["12", "S√£o Paulo", "S√£o Jos√© dos Campos/Taubat√©/Jacare√≠/Guaratinguet√°"],
                        ["13", "S√£o Paulo", "Santos/S√£o Vicente/Praia Grande/Cubat√£o/Itanha√©m/Peru√≠be/Registro"],
                        ["14", "S√£o Paulo", "Bauru/Ja√∫/Mar√≠lia/Len√ß√≥is Paulista/Lins/Botucatu/Ourinhos/Avar√©"],
                        ["15", "S√£o Paulo", "Sorocaba/Itapetininga/Itapeva"],
                        ["16", "S√£o Paulo", "Ribeir√£o Preto/Franca/Araraquara"],
                        ["17", "S√£o Paulo", "S√£o Jos√© do Rio Preto/Barretos/Fernand√≥polis"],
                        ["18", "S√£o Paulo", "Presidente Prudente/Ara√ßatuba/Birigui/Assis"],
                        ["19", "S√£o Paulo", "Campinas/Piracicaba/Limeira/Americana/Sumar√©"],
                        ["21", "Rio de Janeiro", "Rio de Janeiro/Niter√≥i/S√£o Gon√ßalo/Duque de Caxias/Nova Igua√ßu"],
                        ["22", "Rio de Janeiro", "Campos dos Goytacazes/Maca√©/Cabo Frio/Nova Friburgo"],
                        ["24", "Rio de Janeiro", "Volta Redonda/Barra Mansa/Petr√≥polis"],
                        ["27", "Esp√≠rito Santo", "Vit√≥ria/Serra/Vila Velha/Linhares"],
                        ["28", "Esp√≠rito Santo", "Cachoeiro de Itapemirim"],
                        ["31", "Minas Gerais", "Belo Horizonte/Contagem/Betim"],
                        ["32", "Minas Gerais", "Juiz de Fora/Barbacena"],
                        ["33", "Minas Gerais", "Governador Valadares/Te√≥filo Otoni/Caratinga/Manhua√ßu"],
                        ["34", "Minas Gerais", "Uberl√¢ndia/Uberaba/Araguari/Arax√°"],
                        ["35", "Minas Gerais", "Passos/Po√ßos de Caldas/Pouso Alegre/Varginha/Itajub√°"],
                        ["37", "Minas Gerais", "Divin√≥polis/Ita√∫na/Formiga/Capit√≥lio"],
                        ["38", "Minas Gerais", "Montes Claros/Serro/Janu√°ria"],
                        ["41", "Paran√°", "Curitiba/S√£o Jos√© dos Pinhais/Paranagu√°"],
                        ["42", "Paran√°", "Ponta Grossa/Castro/Uni√£o da Vit√≥ria"],
                        ["43", "Paran√°", "Londrina/Arapongas/Assa√≠/Jacarezinho/Jandaia do Sul"],
                        ["44", "Paran√°", "Maring√°/Campo Mour√£o/Astorga"],
                        ["45", "Paran√°", "Cascavel/Toledo/Medianeira"],
                        ["46", "Paran√°", "Francisco Beltr√£o/Pato Branco/Palmas/Pinh√£o"],
                        ["47", "Santa Catarina", "Joinville/Blumenau/Balne√°rio Cambori√∫"],
                        ["48", "Santa Catarina", "Florian√≥polis/S√£o Jos√©/Crici√∫ma"],
                        ["49", "Santa Catarina", "Chapec√≥/Lages/Conc√≥rdia"],
                        ["51", "Rio Grande do Sul", "Porto Alegre/Canoas/Esteio/Torres"],
                        ["53", "Rio Grande do Sul", "Pelotas/Rio Grande/Bag√©/Acegu√°/Chu√≠"],
                        ["54", "Rio Grande do Sul", "Caxias do Sul/Vacaria/Veran√≥polis"],
                        ["55", "Rio Grande do Sul", "Santa Maria/Uruguaiana/Santana do Livramento"],
                        ["61", "Distrito Federal", "Bras√≠lia"],
                        ["62", "Goi√°s", "Goi√¢nia/An√°polis/Goi√°s/Piren√≥polis"],
                        ["63", "Tocantins", "Palmas/Aragua√≠na/Gurupi"],
                        ["64", "Goi√°s", "Rio Verde/Jata√≠/Caldas Novas/Catal√£o"],
                        ["65", "Mato Grosso", "Cuiab√°/V√°rzea Grande/C√°ceres"],
                        ["66", "Mato Grosso", "Rondon√≥polis/Sinop/Barra do Gar√ßas"],
                        ["67", "Mato Grosso do Sul", "Campo Grande/Dourados/Corumb√°/Tr√™s Lagoas"],
                        ["68", "Acre", "Rio Branco/Cruzeiro do Sul"],
                        ["69", "Rond√¥nia", "Porto Velho/Ji-Paran√°/Ariquemes"],
                        ["71", "Bahia Bahia", "Salvador/Cama√ßari/Lauro de Freitas"],
                        ["73", "Bahia Bahia", "Itabuna/Ilh√©us/Porto Seguro/Jequi√©"],
                        ["74", "Bahia Bahia", "Juazeiro/Xique-Xique"],
                        ["75", "Bahia Bahia", "Feira de Santana/Alagoinhas/Len√ß√≥is"],
                        ["77", "Bahia Bahia", "Vit√≥ria da Conquista/Barreiras/Correntina"],
                        ["79", "Sergipe", "Aracaju/Lagarto/Itabaiana"],
                        ["81", "Pernambuco", "Recife/Jaboat√£o dos Guararapes/Goiana/Gravat√°/Paulista"],
                        ["82", "Alagoas", "Macei√≥/Arapiraca/Palmeira dos √çndios/Penedo"],
                        ["83", "Para√≠ba", "Jo√£o Pessoa/Campina Grande/Patos/Sousa/Cajazeiras"],
                        ["84", "Rio Grande do Norte", "Natal/Mossor√≥/Parnamirim/Caic√≥"],
                        ["85", "Cear√°", "Fortaleza/Caucaia/Russas/Maracana√∫"],
                        ["86", "Piau√≠", "Teresina/Parna√≠ba/Piripiri/Campo Maior/Barras"],
                        ["87", "Pernambuco", "Petrolina/Salgueiro/Arcoverde"],
                        ["88", "Cear√°", "Juazeiro do Norte/Crato/Sobral/Itapipoca/Iguatu/Quixad√°"],
                        ["89", "Piau√≠", "Picos/Floriano/Oeiras/S√£o Raimundo Nonato/Corrente"],
                        ["91", "Par√°", "Bel√©m/Ananindeua/Castanhal/Abaetetuba/Bragan√ßa"],
                        ["92", "Amazonas", "Manaus/Iranduba/Parintins/Itacoatiara/Mau√©s/Borba"],
                        ["93", "Par√°", "Santar√©m/Altamira/Oriximin√°/Itaituba/Jacareacanga"],
                        ["94", "Par√°", "Marab√°/Tucuru√≠/Parauapebas/Reden√ß√£o/Santana do Araguaia"],
                        ["95", "Roraima", "Boa Vista/Rorain√≥polis/Caracara√≠/Alto Alegre/Mucaja√≠"],
                        ["96", "Amap√°", "Macap√°/Santana/Laranjal do Jari/Oiapoque/Cal√ßoene"],
                        ["97", "Amazonas", "Tef√©/Coari/Tabatinga/Manicor√©/Humait√°/L√°brea"],
                        ["98", "Maranh√£o", "S√£o Lu√≠s/S√£o Jos√© de Ribamar/Pa√ßo do Lumiar/Pinheiro/Santa In√™s"],
                        ["99", "Maranh√£o", "Imperatriz/Caxias/Timon/Cod√≥/A√ßail√¢ndia"]
                      ])


#%%
df['estado'] = df.merge(df_ddd, left_on='uf', right_on='Prefixo')['Estado']


#%%
uf = df.groupby(['estado']).size().sort_values(ascending=False).reset_index(name="Posts por estado")
printBig('{:d} dos 26 estados postaram'.format(uf.index.size))


#%%
uf.set_index('estado')

#%% [markdown]
# ### Quem divulga mais links para assinar outros grupos

#%%



#%%


#%% [markdown]
#
#
# ### Links indicados
#
#%% [markdown]
# ## Nuvem de palavras

